{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 0 - DATA SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module scrapes data for <b>stock - APPLE</b> from Reuters (e.g.https://www.reuters.com/news/archive/apple?view=page&page=2&pageSize=50\n",
    "and saves the results as csv that contains the following columns:\n",
    "* News Article Title \n",
    "* Published Date\n",
    "\n",
    "Parsing is done with BeautifulSoup library (`pip install bs4` to get it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reuters(page_no):\n",
    "    \n",
    "    #specify the url\n",
    "    quote_page = 'https://www.reuters.com/news/archive/apple?view=page&page=' + str(page_no) + '&pageSize=10'\n",
    "    #quote_page = 'https://www.reuters.com/news/archive/facebook?view=page&page=' + str(page_no) + '&pageSize=50'\n",
    "\n",
    "    \n",
    "    #query the website and return the html to the variable ‘page’\n",
    "    page = urllib2.urlopen(quote_page)\n",
    "    \n",
    "    #parse the html using beautiful soup and store in variable `soup`\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    #collect story title and date attributes\n",
    "    name_box = list(soup.find_all('h3', attrs={'class': 'story-title'}))\n",
    "    date_box = list(soup.find_all('span', attrs = {'class':'timestamp'}))\n",
    "    \n",
    "    #Store the titles and dates in two lists\n",
    "    name_box_stripped = [name.text.strip() for name in name_box]\n",
    "    del name_box_stripped[-3:]\n",
    "    date_box_stripped = [date.text.strip() for date in date_box]\n",
    "    \n",
    "    #return the lists \n",
    "    return name_box_stripped, date_box_stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection():\n",
    "    \n",
    "    quote_page = 'https://www.reuters.com/news/archive/apple?view=page&page=' + str(3) + '&pageSize=10'\n",
    "\n",
    "    #query the website and return the html to the variable ‘page’\n",
    "    page = urllib2.urlopen(quote_page)\n",
    "\n",
    "    all_titles = []\n",
    "    all_dates = []\n",
    "\n",
    "    #Scraping from page 3 to 83\n",
    "    for i in range(3,83):\n",
    "        titles, dates = scrape_reuters(i)\n",
    "        all_titles += titles\n",
    "        all_dates += dates\n",
    "\n",
    "    #Store all the data in a dataframe\n",
    "    if (len(all_titles) == len(all_dates)):\n",
    "\n",
    "        news_headlines_apple = pd.DataFrame({'Article_Title': all_titles, 'Published_date': all_dates, })\n",
    "\n",
    "\n",
    "    #Split the dataset into train/test and validate portions and store them as csv files\n",
    "    news_apple_test = news_headlines_apple[:799].copy()\n",
    "    news_apple_test.to_csv(\"/Users/aishwaryagunashekar/Desktop/Stock_Market_Project/Data/scraped_news_apple_test.csv\",index=False)\n",
    "    news_headlines_apple.to_csv(\"/Users/aishwaryagunashekar/Desktop/Stock_Market_Project/Data/scraped_news_apple.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the scraping, data collection and storing. \n",
    "\n",
    "data_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION \n",
    "\n",
    "\n",
    "We have a dataset that contains news titles and along with its dates for the company - APPLE. The dataset is now prepared for use in a Data Science project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
